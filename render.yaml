services:
  # Reddit Scraper Worker Service
  - type: worker
    name: reddit-scraper
    runtime: python
    repo: https://github.com/your-repo/b9_dashboard
    branch: main
    rootDir: scraper
    buildCommand: pip install -r requirements.txt
    startCommand: python reddit_scraper.py
    envVars:
      # Supabase Configuration
      - key: SUPABASE_URL
        sync: false
      - key: SUPABASE_SERVICE_ROLE_KEY
        sync: false
      - key: SUPABASE_ANON_KEY
        sync: false

      # Redis Configuration (optional)
      - key: REDIS_URL
        sync: false

      # Monitoring Configuration
      - key: LOG_LEVEL
        value: info
      - key: ENABLE_METRICS
        value: "true"

      # Scraper Configuration
      - key: AUTO_START
        value: "true"
      - key: BATCH_SIZE
        value: "10"
      - key: MIN_DELAY_SECONDS
        value: "2.5"
      - key: MAX_DELAY_SECONDS
        value: "6.0"
      - key: MAX_REQUESTS_PER_MINUTE
        value: "100"
      - key: MAX_DAILY_REQUESTS
        value: "50000"

      # Python Environment
      - key: PYTHONUNBUFFERED
        value: "1"

    # Health check to ensure service stays running
    healthCheckPath: /health

    # Auto-deploy settings
    autoDeploy: true

    # Resource allocation (adjust based on needs)
    plan: starter # Options: starter, standard, pro, pro_plus

    # Region settings
    region: oregon # Options: oregon, ohio, virginia, frankfurt, singapore

  # Redis Cache Service (optional - for future enhancements)
  - type: redis
    name: b9-dashboard-redis
    plan: starter # Options: starter, standard, pro
    maxmemoryPolicy: allkeys-lru
    ipAllowList: [] # Leave empty for internal access only