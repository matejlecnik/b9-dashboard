---
alwaysApply: true
---
## ğŸ§  Stack

- **Frontend**: Next.js 15 + TypeScript + shadcn/ui (Vercel)
- **Backend**: Python FastAPI + Redis (Render)
- **Database**: Supabase PostgreSQL
- **Architecture**: Dashboard â†’ API â†’ Supabase + Background Workers

---

## ğŸ”¥ Build Error Fixes

**Thousands of build errors are normal** - here's how to fix them:

### Nuclear Option
```bash
rm -rf node_modules package-lock.json
npm cache clean --force
npm install --legacy-peer-deps

# Still broken?
npm install --force
npm install --legacy-peer-deps --no-optional
```

### Common Fixes
```bash
npm install next@15.5.x react@18.x react-dom@18.x --save-exact
npm install typescript@5.x --save-exact
npm install @radix-ui/react-* --legacy-peer-deps
npm install eslint-config-next@15.x --save-exact
```

### Error Patterns
- "Module not found" â†’ Check import paths
- "Peer dependency" â†’ Use `--legacy-peer-deps`
- "Cannot resolve" â†’ Delete node_modules, reinstall
- "TypeScript error" â†’ Check tsconfig.json paths

### Emergency: `npm install --legacy-peer-deps --force --no-audit --no-fund`

---

## ğŸ¤– AI-Generated Codebase

**CRITICAL**: Entire codebase built by AI. Expect:
- Inconsistent patterns
- Redundant imports (might break if removed)
- Over-engineered solutions
- Missing error handling
- Conflicting dependencies

**Before changing anything**:
1. Review ALL imports
2. Test in isolation
3. Verify backend endpoints exist
4. Check TypeScript strict mode

---

## ğŸš€ Setup

**Prerequisites**: Node.js 20+, Python 3.12+

```bash
# Clone
git clone <repo-url> && cd B9-Dashboard

# Frontend
cd dashboard && npm install && cp .env.example .env.local
npm run dev  # localhost:3000

# Backend
cd api && pip3 install -r requirements.txt && cp .env.example .env
python3 main.py  # localhost:8000
```

**Environment Variables**:
```bash
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_SERVICE_ROLE_KEY=your-service-role-key
NEXT_PUBLIC_SUPABASE_URL=same-as-above
NEXT_PUBLIC_SUPABASE_ANON_KEY=your-anon-key
OPENAI_API_KEY=your-openai-key
REDIS_URL=redis://localhost:6379
```

---

## ğŸ—ï¸ Project Structure

```
B9-Dashboard/
â”œâ”€â”€ dashboard/               # Next.js frontend
â”‚   â”œâ”€â”€ src/app/(dashboard)/ # Main pages (review, categorization, posting, etc.)
â”‚   â””â”€â”€ src/components/      # Reusable UI
â”œâ”€â”€ api/                     # Python FastAPI backend
â”‚   â”œâ”€â”€ services/            # Business logic (categorization, scraping, users)
â”‚   â”œâ”€â”€ tasks/               # Background jobs
â”‚   â””â”€â”€ main.py             # FastAPI app
â”œâ”€â”€ scraper/                 # Reddit data collection
â””â”€â”€ config/                  # Setup files
```

**Note**: `/scripts` folder removed - everything now goes through API endpoints.

---

## ğŸ’¼ The Business Context (Important!)

### What B9 Agency Actually Does
This is an **internal tool for B9 Agency ONLY** - not a public platform or SaaS product.

1. **Discover** new subreddits through Reddit scraping and analysis
2. **Score** each subreddit based on proprietary algorithms (your secret sauce)
3. **Review** them manually (Ok/No Seller/Non Related/User Feed)
4. **Track** top-performing subreddits for OnlyFans marketing campaigns
5. **Keep tabs** on community changes and performance over time

### Reality Check - The Numbers
- **5,819 subreddits** discovered and analyzed
- **Only 10-20% are actually useful** (you mentioned this realistic conversion rate)
- **500+ "Ok" subreddits** have been approved for campaigns
- **Scraper currently doesn't work reliably** (known issue)
- **Site breaks frequently** when adding new features

### Internal Team Workflow
1. Agency team logs in â†’ reviews new discoveries
2. Analyzes subreddit scores â†’ identifies top performers
3. Manually reviews questionable ones â†’ categorizes appropriately
4. Uses approved subreddits for client campaigns
5. Tracks performance and adjusts scoring algorithm

### Future Vision - Multiple Dashboards
This Reddit dashboard is just the beginning. Plans include:
- **Multiple dashboard instances** with different Supabase URLs
- **Different social media platforms** (Instagram, TikTok, etc.)
- **Custom dashboards** for whatever the agency needs
- **Scalable architecture** to handle multiple data sources

This context matters because every feature decision should help B9 Agency find and track the best subreddits more efficiently.

---


## âš¡ **STANDARDIZED PATTERNS** (Required Reading)

After resolving persistent errors with React 19 + Next.js 15, these patterns are **MANDATORY** to prevent future issues:

### ğŸ› ï¸ **Server Actions Pattern (FIXED)**
```typescript
// Server Action File (actions.ts)
'use server'

import { revalidatePath } from 'next/cache'
import { redirect } from 'next/navigation'

export async function actionName(
  prevState: { error: string | null },
  formData: FormData
) {
  // Implementation here
  
  // Always handle errors properly
  if (error) {
    return { error: "User-friendly message" }
  }
  
  // On success, revalidate and redirect
  revalidatePath('/', 'layout')
  redirect('/dashboard')
}
```

```typescript
// Client Component (page.tsx)
'use client'

import { useFormState } from 'react-dom' // â† NEVER use useActionState
import { actionName } from './actions'

export default function MyPage() {
  const [state, formAction] = useFormState(actionName, { error: "" })
  
  return (
    <form action={formAction}>
      {state?.error && <div>{state.error}</div>}
      {/* Form fields */}
    </form>
  )
}
```

### ğŸš¨ **NEVER Use These (Causes Errors)**
- âŒ `useActionState` from React (experimental, incompatible with Next.js 15)
- âŒ Version mismatches in package.json
- âŒ Mixing server/client boundaries incorrectly

### âœ… **ALWAYS Use These (Stable)**
- âœ… `useFormState` from `react-dom` for server actions
- âœ… `React.startTransition()` for performance-critical state updates
- âœ… Exact version pinning for Next.js in package.json
- âœ… `'use server'` and `'use client'` directives explicitly

### ğŸ”§ **Performance Patterns**
```typescript
// For frequent state updates (like search, filters)
React.startTransition(() => {
  setSearchQuery(newValue)
  setFilters(newFilters)
})

// For expensive computations
const expensiveValue = useMemo(() => {
  return computeExpensiveValue(data)
}, [data])

// For optimized event handlers
const handleChange = useCallback((value) => {
  React.startTransition(() => {
    onChange(value)
  })
}, [onChange])
```

### ğŸ“‹ **Pre-Commit Checklist**
Before every commit, ensure:
- [ ] No experimental React hooks used
- [ ] All server actions use `useFormState`
- [ ] Package.json versions match installed versions
- [ ] `npm run build` succeeds
- [ ] No console errors in development

---

## ğŸ”¥ Common Tasks

**New Dashboard Page**: Create in `dashboard/src/app/(dashboard)/your-page/`, add README.md, update navigation
**New API Endpoint**: Add to `api/main.py`, use error handling + rate limiting, test with curl
**Categorization**: `curl -X POST localhost:8000/api/categorization/start -d '{"batchSize":30}'`

---

## ğŸ“Š Performance

**Frontend**: Use `react-window` for >1000 rows, `useMemo`/`React.memo`, proper caching
**Backend**: Index queries, limit results, Redis caching, Reddit 100req/min per account  
**Database**: Always `LIMIT` queries, use indexes

---

## âš ï¸ Known Issues

**Major Problems**:
- **Scraper doesn't work** (proxy config, API creds, account rotation)
- **Site breaks when adding features** (architecture fragility)
- **Build errors constantly** (dependency conflicts)
- **Low conversion rate** (10-20% useful discoveries)

**Before Development**: `npm run build`, test scraper, verify DB connection
**Emergency**: Delete node_modules, `npm install --legacy-peer-deps`, `git checkout -- files`

---

## ğŸš¨ Gotchas

**Reddit**: Rate limits per account (10 accounts = 1000req/min), use `display_name`, check `[removed]`
**Next.js**: Use `'use client'`, `NEXT_PUBLIC_` for client vars, `next/image`
**Supabase**: RLS policies, clean up subscriptions, connection pooling
**Errors**: Check import paths, rate_limit decorator, null checks, env vars

---

## ğŸ“ˆ Monitoring

**Metrics**: API <200ms, Reddit <1000req/min, Errors <1%
**Debug**: `npm run dev`, `LOG_LEVEL=debug python3 main.py`  
**Logs**: Browser console, Render logs, Supabase dashboard

---

## ğŸ¯ Pre-Commit Checklist

- [ ] `npm run build` + `npm run lint` + `npx tsc --noEmit`
- [ ] Review imports, test existing pages, verify endpoints exist  
- [ ] Real data tested, error handling added, README updated
- [ ] No secrets committed

---

## ğŸ¤ Getting Help

Check CLAUDE.md â†’ folder READMEs â†’ browser console/API logs
Workflow: discover â†’ review â†’ categorize â†’ recommend
Priority: creator experience for OnlyFans marketing

---

## ğŸ† Quick Wins

Loading states, user-friendly errors, data validation, performance optimization, test coverage

---

## ğŸ“š Resources

**Docs**: Next.js, FastAPI, Supabase, Reddit API docs  
**Internal**: `api/README.md`, component READMEs, Supabase dashboard, Render/Vercel

---

## ğŸ¬ Recent Changes

- Manual research (4hrs) â†’ automated (10min)
- Scripts â†’ API endpoints  
- Railway â†’ Render deployment
- Removed AI review (categorization only)
- **FIXED: React 19 + Next.js 15 compatibility**

---

*Built for B9 Agency - Optimizing OnlyFans marketing through Reddit intelligence.*